{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install all needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch_geometric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import everything that is needed and choose wheter to work on a GPU or a CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch import Tensor\n",
    "from torch.functional import F\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.datasets import QM9\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch_geometric.utils import scatter\n",
    "from torch_geometric.nn import MessagePassing\n",
    "import torch.nn.init as init\n",
    "from typing import Union, Optional\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`load_data()` is a simple dataloader that splits the data in a reproducible way by setting the seed of the generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path, batch_size, train_size=0.8, val_size=0.1):\n",
    "    ### load data\n",
    "    dataset = QM9(root=path)\n",
    "\n",
    "    # Calculate split lengths\n",
    "    total_length = len(dataset)\n",
    "    train_length = int(train_size * total_length)\n",
    "    val_length = int(val_size * total_length)\n",
    "    test_length = total_length - train_length - val_length\n",
    "\n",
    "    # Perform random split\n",
    "    train_set, val_set, test_set = torch.utils.data.random_split(dataset,\n",
    "                                                                    [train_length, val_length, test_length],\n",
    "                                                                    generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size)\n",
    "    val_loader = DataLoader(val_set, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size)\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the parameter for which we train for. Detailed list in readme and in [PyG documentation](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.datasets.QM9.html). Indexes 0 and 5 in the PyG dataset have to be treated specially and we have not implemented this part.\n",
    "\n",
    "Also, we need to choos hyperparameters for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = 2 # 0..15, except 0 and 5, see readme\n",
    "config = {\n",
    "    \"param\": param,\n",
    "    \"name\":  f\"cafa-param-{param}-std\",\n",
    "    \"batch_size\": 100,\n",
    "    \"train_size\": 0.8,\n",
    "    \"test_size\":  0.1,\n",
    "\n",
    "    \"num_atoms\":      10,\n",
    "    \"num_embeddings\": 128,\n",
    "    \"cutoff_dist\":    5,\n",
    "    \"hidden_out_dim\": 128,\n",
    "\n",
    "    \"epochs\":         500,\n",
    "    \"learning_rate\":  5e-4,\n",
    "    \"weight_decay\":   0.01,\n",
    "    \"smoothing_factor\": 0.7,\n",
    "    \"device\":           device\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = load_data(f\"./data\", config[\"batch_size\"], config[\"train_size\"], config[\"test_size\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyG allows us to create special message passing layers by creating a class that defines the messages, aggregation and update functions.\n",
    "1. We compute the edges of the nearest neighbours that are closer than the cutoff distance 5 \\AA.\n",
    "2. `propagate()` function calls message, aggregate and update based on the first argument that defines the edges of the graph\n",
    "3. `message()` creates the message from each node to the neighbours it is connected to.\n",
    "4. `aggregate()` aggregates the messages that are sent to the same atom by summing all the individual messages together. The sum is to be added to the previous scalar and vector represenatations.\n",
    "5. `update()` is a function of the aggregated messages for each node and produces $\\Delta s_i$ and $\\Delta\\mathbf{v}_i$ to be added to the previous represantations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MessageLayer(MessagePassing):\n",
    "\n",
    "\n",
    "    propagate_type = {\"neighbours\": Tensor, \"s\": Optional[Tensor], \"v\": Optional[Tensor], \"r\": Optional[Tensor], \"neighbours\": Optional[Tensor]}\n",
    "\n",
    "    def __init__(self, num_embeddings, cutoff_dist, device):\n",
    "        super().__init__(flow=\"source_to_target\")\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        self.num_embeddings = num_embeddings\n",
    "        self.cutoff_dist = cutoff_dist\n",
    "\n",
    "        # message block\n",
    "        self.linear_phi1 = nn.Linear(self.num_embeddings, self.num_embeddings)\n",
    "        self.linear_phi2 = nn.Linear(self.num_embeddings, 3*self.num_embeddings)\n",
    "        self.linear_W = nn.Linear(20, 3*self.num_embeddings)\n",
    "\n",
    "        # update block\n",
    "        self.linear_U = nn.Linear(self.num_embeddings, self.num_embeddings, bias=False)\n",
    "        self.linear_V = nn.Linear(self.num_embeddings, self.num_embeddings, bias=False)\n",
    "        self.linear_update1 = nn.Linear(2*self.num_embeddings, self.num_embeddings)\n",
    "        self.linear_update2 = nn.Linear(self.num_embeddings, 3*self.num_embeddings)\n",
    "        self.initialize_weights()\n",
    "\n",
    "    # embeddings :      [natoms, num_embeddings]\n",
    "    # equivar_repr :    [3, natoms, num_embeddings]\n",
    "    # pos :             [natoms, 3]\n",
    "    # batch :           [natoms]\n",
    "    def forward(self, embeddings: Tensor, equivar_repr: Tensor, pos: Tensor, batch: Tensor) -> Union[Tensor, Tensor]:\n",
    "        neighbours = self.get_neighbours_as_edge_index(pos, batch, self.cutoff_dist)\n",
    "\n",
    "        return self.propagate(neighbours, s=embeddings, v=equivar_repr, r=pos, neighbours=neighbours, size=None)\n",
    "\n",
    "    # _j is a neighbour, _i is the atom\n",
    "    # s_j : [num_edges, num_embeddings]\n",
    "    # v_j : [3, num_edges, num_embeddings]\n",
    "    # r_i : [num_edges, 3]\n",
    "    # r_j : [num_edges, 3]\n",
    "    def message(self, s_j, v_j, r_i, r_j):\n",
    "        phi = self.linear_phi1(s_j) # [num_edges, num_embeddings]\n",
    "        phi = F.silu(phi)\n",
    "        phi = self.linear_phi2(phi) # [num_edges, 3*num_embeddings]\n",
    "\n",
    "        rel_pos = r_i - r_j         # [num_edges, 3]\n",
    "        distance = torch.norm(rel_pos, dim=1) # [num_edges]\n",
    "        cutoff = distance.detach().clone()\n",
    "        cutoff[distance <= self.cutoff_dist] = 0.5*(torch.cos(torch.pi * distance[distance <= self.cutoff_dist] / self.cutoff_dist) + 1)\n",
    "        cutoff[distance > 0] = 0\n",
    "        RBF = cutoff[:, None] * torch.sin(torch.arange(1, 21, device=self.device)[None, :] * torch.pi * distance[:, None] / self.cutoff_dist) / distance[:, None] # [num_edges, 20]\n",
    "        W = self.linear_W(RBF)      # [num_edges, 3*num_embeddings]\n",
    "\n",
    "        split = torch.mul(phi, W)   # [num_edges, 3*num_embeddings]\n",
    "        split1 = split[:, :self.num_embeddings]\n",
    "        split2 = split[:, self.num_embeddings:2*self.num_embeddings]\n",
    "        split3 = split[:, 2*self.num_embeddings:]\n",
    "\n",
    "        delta_s_ij = split1 # [num_edges, num_embeddings]\n",
    "\n",
    "        v_j = v_j.permute([1,2,0]) # [num_edges, num_embeddings, 3]\n",
    "        delta_v_ij = torch.mul(v_j, split2[:, :, None]) \\\n",
    "                            + torch.mul(torch.mul(split3[:, :, None], rel_pos[:, None, :]), distance[:, None, None]) # [num_edges, num_embeddings, 3]\n",
    "        delta_v_ij = delta_v_ij.permute([2, 0, 1]) # [3, natoms, num_embeddings]\n",
    "\n",
    "        return delta_s_ij, delta_v_ij\n",
    "\n",
    "    # _j is a neighbour, _i is the atom\n",
    "    # s_i : [num_edges, num_embeddings]\n",
    "    # v_i : [3, num_edges, num_embeddings]\n",
    "    def aggregate(self, message, neighbours, s, v):\n",
    "        delta_s_ij, delta_v_ij = message\n",
    "\n",
    "        delta_s_i = scatter(delta_s_ij, neighbours[1], dim=0, reduce=\"sum\") # [natoms, num_embeddings]\n",
    "        delta_v_i = scatter(delta_v_ij, neighbours[1], dim=1, reduce=\"sum\") # [3, natoms, num_embeddings]\n",
    "\n",
    "        s_i = s + delta_s_i\n",
    "        v_i = v + delta_v_i\n",
    "\n",
    "        return s_i, v_i\n",
    "\n",
    "    def update(self, agg_message, s, v):\n",
    "        s_i, v_i = agg_message\n",
    "        U = self.linear_U(v_i) # [3, natoms, num_embeddings]\n",
    "        V = self.linear_V(v_i) # [3, natoms, num_embeddings]\n",
    "\n",
    "        stack = torch.cat([s_i, torch.norm(V, dim=0)], dim=1) # [natoms, 2*num_embeddings]\n",
    "\n",
    "        stack = self.linear_update1(stack) # [natoms, num_embeddings]\n",
    "        stack = F.silu(stack)\n",
    "        split = self.linear_update2(stack) # [natoms, 3*num_embeddings]\n",
    "\n",
    "        split1 = split[:, :self.num_embeddings]  # First part, contains the first 128 elements in the second dimension\n",
    "        split2 = split[:, self.num_embeddings: 2*self.num_embeddings]  # Second part, contains the next 128 elements\n",
    "        split3 = split[:, 2*self.num_embeddings:]  # Third part, contains the last 128 elements\n",
    "\n",
    "        delta_s = split2 + torch.sum(U * V, dim=0) * split3 # [natoms, num_embeddings]\n",
    "\n",
    "        delta_v = torch.mul(U, split1[None, :, :]) # [3, natoms, num_embeddings]\n",
    "\n",
    "        s += delta_s\n",
    "        v += delta_v\n",
    "\n",
    "        return s, v\n",
    "\n",
    "    def get_neighbours_as_edge_index(self, pos, batch, cutoff_dist):\n",
    "        # count atoms in each molecule\n",
    "        unique = torch.unique(batch, return_counts=True)\n",
    "        # i-th row is for i-th atom in data.z, ij element is distance between i-th and j-th atom\n",
    "        distances = torch.cdist(pos, pos, p=2)\n",
    "        # select atoms\n",
    "        neighbours = torch.where(distances <= cutoff_dist, 1, 0)\n",
    "        # mask other atoms\n",
    "        neighbours = neighbours * torch.block_diag(*[torch.ones((u,u)) for u in unique[1]]).to(self.device)\n",
    "        # exclude itself\n",
    "        neighbours = neighbours - torch.eye(neighbours.shape[0], device=self.device)\n",
    "        # get neighbours in the form of [2, num_edges]\n",
    "        neighbours = neighbours.nonzero(as_tuple=False).t()\n",
    "        neighbours = torch.index_select(neighbours, dim=0, index=torch.tensor([1,0], device=self.device)).type(torch.LongTensor).to(self.device)\n",
    "\n",
    "        return neighbours\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                # Kaiming Initialization for linear layers\n",
    "                init.kaiming_uniform_(m.weight, nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can define the model with the conventional PyTorch methods. The output is one number for each molecule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaiNN(nn.Module):\n",
    "    def __init__(self, num_atoms, num_embeddings, cutoff_dist, hidden_out_dim, device, message_layers=3):\n",
    "        super().__init__()\n",
    "        self.num_embeddings = num_embeddings\n",
    "        self.cutoff_dist = cutoff_dist\n",
    "        self.device = device\n",
    "        self.message_layers = message_layers\n",
    "\n",
    "        self.embeddings = nn.Embedding(num_atoms, num_embeddings, padding_idx=0)\n",
    "        # self.message = Message(num_embeddings, cutoff_dist, device)\n",
    "        # self.update = Update(num_embeddings, cutoff_dist, device)\n",
    "\n",
    "        self.messagelayer = MessageLayer(num_embeddings, cutoff_dist, device)\n",
    "\n",
    "        # # multiple message passing layers\n",
    "        # self.messageLayers = []\n",
    "        # for _ in range(message_layers):\n",
    "        #     self.messageLayers.append(MessageLayer(num_embeddings, cutoff_dist, device))\n",
    "\n",
    "        self.linear_out1 = nn.Linear(num_embeddings, hidden_out_dim)\n",
    "        self.linear_out2 = nn.Linear(hidden_out_dim, 1)\n",
    "\n",
    "    def forward(self, data: Batch) -> Tensor:\n",
    "        # 1. Initialize inputs (s and v)\n",
    "        embeddings = self.embeddings(data.z) # [batch_size, num_embeddings]\n",
    "        equivariant_repr = torch.zeros((3, len(data.z), self.num_embeddings), device=self.device)\n",
    "\n",
    "        # 2. Send messages and make updates\n",
    "        for _ in range(self.message_layers):\n",
    "            embeddings, equivariant_repr = self.messagelayer(embeddings, equivariant_repr, data.pos, data.batch)\n",
    "            # embeddings, equivariant_repr = self.message(embeddings, equivariant_repr, data.pos, data.batch)\n",
    "            # embeddings, equivariant_repr = self.update(embeddings, equivariant_repr, data.pos, data.batch)\n",
    "\n",
    "        # For passing through multiple message passing layers use:\n",
    "        # for messagelayer in self.messageLayers:\n",
    "        #     embeddings, equivariant_repr = messagelayer(embeddings, equivariant_repr, data.pos, data.batch)\n",
    "\n",
    "        # 3. Final linear layer\n",
    "        out = self.linear_out1(embeddings) # [batch_size, num_embeddings] -> [batch_size, hidden_out_dim]\n",
    "        out = F.silu(out)\n",
    "        out = self.linear_out2(out) # [batch_size, 1]\n",
    "\n",
    "        out = scatter(out, data.batch, dim=0, reduce=\"sum\")\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PaiNN(num_atoms=config[\"num_atoms\"], num_embeddings=config[\"num_embeddings\"],\n",
    "              cutoff_dist=config[\"cutoff_dist\"], hidden_out_dim=config[\"hidden_out_dim\"], device=device)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"], weight_decay=config[\"weight_decay\"])\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model, optimizer, criterion, scheduler, train_loader, val_loader, config, save_path, from_epoch=0, smoothed_val_loss=None):\n",
    "    epochs = config[\"epochs\"]\n",
    "    device = torch.device(config[\"device\"])\n",
    "    param = config[\"param\"]\n",
    "    smoothing_factor = config[\"smoothing_factor\"]\n",
    "\n",
    "    mean = 0\n",
    "    length = 0\n",
    "    for batch in train_loader:\n",
    "        mean += batch.y[:, param].sum()\n",
    "        length += len(batch.y[:, param])\n",
    "    for batch in val_loader:\n",
    "        mean += batch.y[:, param].sum()\n",
    "        length += len(batch.y[:, param])\n",
    "    mean = mean / length\n",
    "    print(f\"Mean of data {mean}\")\n",
    "\n",
    "    std = 0\n",
    "    for batch in train_loader:\n",
    "        std += torch.sum((batch.y[:, param] - mean)**2)\n",
    "    for batch in val_loader:\n",
    "        std += torch.sum((batch.y[:, param] - mean)**2)\n",
    "    std = torch.sqrt(std/(length-1))\n",
    "    print(f\"Standard dev. {std}\")\n",
    "\n",
    "    for epoch in range(from_epoch, epochs):\n",
    "        model.train()\n",
    "        total_train_loss, total_train_mae = 0.0, 0.0\n",
    "\n",
    "\n",
    "        for batch in train_loader:\n",
    "            batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            #Forward pass\n",
    "            std_output = model(batch)\n",
    "            output = std_output.squeeze()*std + mean\n",
    "            # Assuming 'output' and 'batch.y' are aligned for loss calculation\n",
    "            loss = criterion(1000*output, 1000*(batch.y[:, param] - mean)/std)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_train_loss += loss.item()\n",
    "            total_train_mae += F.l1_loss(1000*output*std+mean, 1000*batch.y[:, param]).item()\n",
    "\n",
    "\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        avg_train_mae = total_train_mae / len(train_loader)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Train Loss: {avg_train_loss:.4f}, Train L1 Loss: {avg_train_mae:.4f}' )\n",
    "\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        total_val_loss, total_val_mae = 0.0, 0.0\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                batch.to(device)\n",
    "                std_output = model(batch)\n",
    "                output = std_output.squeeze()*std + mean\n",
    "                loss = criterion(1000*output, 1000*(batch.y[:, param]-mean)/std)\n",
    "                total_val_loss += loss.item()\n",
    "                total_val_mae += F.l1_loss(1000*output, 1000*(batch.y[:, param] - mean)/std).item()\n",
    "\n",
    "\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        avg_val_mae = total_val_mae / len(val_loader)\n",
    "        # Apply exponential smoothing to validation loss\n",
    "        if smoothed_val_loss is None:\n",
    "            smoothed_val_loss = avg_val_loss\n",
    "        else:\n",
    "            smoothed_val_loss = (smoothing_factor * smoothed_val_loss) + ((1 - smoothing_factor) * avg_val_loss)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Validation Loss: {avg_val_loss:.4f}, Validation L1: {avg_val_mae:.4f}, Smoothed Validation Loss: {smoothed_val_loss:.4f}')\n",
    "\n",
    "        # Adjust learning rate based on smoothed validation loss\n",
    "        scheduler.step(smoothed_val_loss)\n",
    "\n",
    "        # wandb.log({\"train_loss\": avg_train_loss, \"train l1 loss\": avg_train_mae, \"val loss\": avg_val_loss, \"val l1 loss\": avg_val_mae, \"smoothed val loss\":smoothed_val_loss })\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            # Save the model\n",
    "            save_dict = {\n",
    "                \"epoch\": epoch,\n",
    "                \"config\": config,\n",
    "                \"model\": model.state_dict(),\n",
    "                \"smoothed_val_loss\": smoothed_val_loss,\n",
    "                \"scheduler\": scheduler.state_dict(),\n",
    "                \"optimizer\": optimizer.state_dict()\n",
    "            }\n",
    "            torch.save(save_dict, f\"{save_path}/epoch_{epoch+1}.pth\")\n",
    "\n",
    "    save_dict = {\n",
    "        \"epoch\": epoch,\n",
    "        \"config\": config,\n",
    "        \"model\": model.state_dict(),\n",
    "        \"smoothed_val_loss\": smoothed_val_loss,\n",
    "        \"scheduler\": scheduler.state_dict(),\n",
    "        \"optimizer\": optimizer.state_dict()\n",
    "    }\n",
    "    torch.save(save_dict, f\"{save_path}/final.pth\")\n",
    "    # wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loop(model, optimizer, criterion, scheduler, train_loader, val_loader, config, \".\",\n",
    "                        from_epoch=0, smoothed_val_loss=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
